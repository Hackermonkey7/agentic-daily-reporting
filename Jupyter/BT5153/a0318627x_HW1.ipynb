{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Xok8NKxtEDMz"
   },
   "source": [
    "## Homework 1: Decoding Strategies and Emoji Classification\n",
    "\n",
    "This homework combines decoding strategies (greedy and temperature sampling) and emoji classification using embeddings.\n",
    "\n",
    "##### Submission Instructions\n",
    "1. Complete all the functions marked with \"Your code here\".\n",
    "2. Run all cells to make sure your outputs are correct.\n",
    "3. Answer all output questions in markdown.\n",
    "4. Due on 13th Feb. 2026, Friday at 23:59pm\n",
    "5. Submit your solution notebook to \"Canvas -> HW1-Assignment\"\n",
    "6. **Prepend your NUS userID to the filename, i.e., \"`a0123456b_HW.ipynb`\"**. Only ipython notebooks are accepted.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p6p-CbvYEDM5"
   },
   "source": [
    "## Part 1: Decoding Strategies (5 pts)\n",
    "In Lecture 3, decoding happens after a final softmax layer, and different strategies can be used.\n",
    "You will implement greedy decoding and temperature sampling, then interpret the outputs.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fidwFByeEDM6"
   },
   "source": [
    "Lecture 3 decoding strategies:\n",
    "- Greedy search: choose the highest-probability token.\n",
    "- Beam search: keep the top-N partial sequences.\n",
    "- Temperature sampling: re-scale logits before sampling.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "USCHQ7XgEDM7"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Example logits (pre-softmax scores) for 10 tokens\n",
    "tokens = [\"token_\" + str(i) for i in range(10)]\n",
    "logits = np.array([5.0, 4.0, 3.0, 2.0, 1.0, 0.5, 0.3, 0.2, 0.1, 0.05], dtype=np.float32)\n",
    "\n",
    "\n",
    "def softmax(x):\n",
    "    \"\"\"Compute a numerically stable softmax for a 1D array.\"\"\"\n",
    "    shifted = x - np.max(x)\n",
    "    exp = np.exp(shifted)\n",
    "    return exp / np.sum(exp)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MzQGq2PcEDM8"
   },
   "source": [
    "### Task 1.1: Implement temperature scaling\n",
    "Complete the function below to apply temperature scaling and return probabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "xclj2WKFEDM_"
   },
   "outputs": [],
   "source": [
    "def apply_temperature(logits, temperature):\n",
    "    \"\"\"Apply temperature scaling to logits and return probabilities.\"\"\"\n",
    "    # Your code here\n",
    "    scaled_logits = logits / temperature\n",
    "    \n",
    "    # Apply softmax to get probabilities\n",
    "    probs = softmax(scaled_logits)\n",
    "    \n",
    "    return probs\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "y8LmCVpoEDNB"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Temperature 0.1 argmax token: token_0 | prob=1.0000\n",
      "Sum of probabilities: 1.0000\n",
      "-\n",
      "Temperature 0.5 argmax token: token_0 | prob=0.8644\n",
      "Sum of probabilities: 1.0000\n",
      "-\n",
      "Temperature 1.0 argmax token: token_0 | prob=0.6195\n",
      "Sum of probabilities: 1.0000\n",
      "-\n",
      "Temperature 2.0 argmax token: token_0 | prob=0.3578\n",
      "Sum of probabilities: 1.0000\n",
      "-\n"
     ]
    }
   ],
   "source": [
    "temperatures = [0.1, 0.5, 1.0, 2.0]\n",
    "\n",
    "for temp in temperatures:\n",
    "    probs = apply_temperature(logits, temp)\n",
    "    top_idx = int(np.argmax(probs))\n",
    "    print(f\"Temperature {temp} argmax token: {tokens[top_idx]} | prob={probs[top_idx]:.4f}\")\n",
    "    print(f\"Sum of probabilities: {np.sum(probs):.4f}\")\n",
    "    print(\"-\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mTc_j9MlEDND"
   },
   "source": [
    "### Task 1.2: Implement greedy decoding\n",
    "Complete the function below to choose the highest-probability token (greedy decoding)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "-icA83m9EDNE"
   },
   "outputs": [],
   "source": [
    "def greedy_decode(probabilities, tokens):\n",
    "    \"\"\"Return the single highest-probability token and its index.\"\"\"\n",
    "    # Your code here\n",
    "    # Find the index of the highest probability\n",
    "    top_index = int(np.argmax(probabilities))\n",
    "    \n",
    "    # Get the corresponding token\n",
    "    top_token = tokens[top_index]\n",
    "    return top_token, top_index\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "CtqAwEpnEDNF"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Temperature 0.1 greedy token: token_0 | prob=1.0000\n",
      "Temperature 0.5 greedy token: token_0 | prob=0.8644\n",
      "Temperature 1.0 greedy token: token_0 | prob=0.6195\n",
      "Temperature 2.0 greedy token: token_0 | prob=0.3578\n"
     ]
    }
   ],
   "source": [
    "for temp in temperatures:\n",
    "    probs = apply_temperature(logits, temp)\n",
    "    top_token, top_idx = greedy_decode(probs, tokens)\n",
    "    print(f\"Temperature {temp} greedy token: {top_token} | prob={probs[top_idx]:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xkAGEj91EDNF"
   },
   "source": [
    "### Task 1.3: Implement sampling from probabilities\n",
    "Complete the sampling function to draw tokens from the distribution.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "VOdnqsp2EDNF"
   },
   "outputs": [],
   "source": [
    "def sample_tokens(probabilities, n_samples=10):\n",
    "    \"\"\"Sample tokens based on their probabilities.\"\"\"\n",
    "    # Your code here\n",
    "    sampled_indices = np.random.choice(len(probabilities),\n",
    "    size=n_samples,\n",
    "    p=probabilities         \n",
    "    )\n",
    "    \n",
    "    # Convert indices to token names\n",
    "    sampled_tokens = np.array([tokens[idx] for idx in sampled_indices])\n",
    "    \n",
    "    return sampled_tokens\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "sms6yulrEDNG"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampling 10 tokens with different temperatures:\n",
      "\n",
      "Temperature 0.1:\n",
      "Samples: ['token_0' 'token_0' 'token_0' 'token_0' 'token_0' 'token_0' 'token_0'\n",
      " 'token_0' 'token_0' 'token_0']\n",
      "Frequency of token_0: 10 out of 10\n",
      "\n",
      "Temperature 0.5:\n",
      "Samples: ['token_0' 'token_1' 'token_0' 'token_0' 'token_0' 'token_0' 'token_0'\n",
      " 'token_0' 'token_0' 'token_0']\n",
      "Frequency of token_0: 9 out of 10\n",
      "\n",
      "Temperature 1.0:\n",
      "Samples: ['token_0' 'token_0' 'token_0' 'token_0' 'token_0' 'token_1' 'token_0'\n",
      " 'token_0' 'token_0' 'token_0']\n",
      "Frequency of token_0: 9 out of 10\n",
      "\n",
      "Temperature 2.0:\n",
      "Samples: ['token_2' 'token_0' 'token_0' 'token_8' 'token_8' 'token_4' 'token_0'\n",
      " 'token_0' 'token_2' 'token_1']\n",
      "Frequency of token_0: 4 out of 10\n"
     ]
    }
   ],
   "source": [
    "print(\"Sampling 10 tokens with different temperatures:\")\n",
    "for temp in temperatures:\n",
    "    probs = apply_temperature(logits, temp)\n",
    "    samples = sample_tokens(probs, n_samples=10)\n",
    "    print(f\"\\nTemperature {temp}:\")\n",
    "    print(f\"Samples: {samples}\")\n",
    "    print(f\"Frequency of token_0: {np.sum(samples == 'token_0')} out of 10\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cf-OsOOJEDNH"
   },
   "source": [
    "### Task 1.4: Output questions\n",
    "Answer the following based on the outputs you observe:\n",
    "1. For which temperature is the distribution most peaked? Why?\n",
    "2. Which temperature shows the most diverse samples?\n",
    "3. Does greedy decoding change with temperature here? Explain based on the outputs.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### your answers here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1->temperature0.1 has the most peaked. when temp i, logits are divided by a small number to widen disparity . so softmaxed values puts all probabilities to the highest token Result: token0 sampled 10 times/10 100% probability token0-0 prob temp=0.1 1.0000.\n",
    "\n",
    "2->Temperature 2.0 has the most variety of samples. Sample 6 different tokens, token0, token1, token2, token4, token_8. The distribution is flattened and tends to favor the winning of lower-ranked tokens.\n",
    "\n",
    "3->No, greedy decoding does not change with temperature. Greedy decode always chooses the token with the highest probable value. The original highest logit value (5.0) for token_0 still makes it the most probable token at each temperature.\n",
    "\n",
    "From the earlier greedy output, all temperatures selected token_0 as the greedy choice\n",
    "\n",
    "Temperature only affects the confidence (probability value), not which token is most likely\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LaBqMYH6EDNH"
   },
   "source": [
    "## Part 2: Emoji Classification (5 pts)\n",
    "Modern business communication often includes emojis, especially in social media and customer interactions.\n",
    "Let's build a system that can suggest appropriate emojis for business communications.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "loyyee-UEDNH"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading weights: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 103/103 [00:00<00:00, 1942.85it/s, Materializing param=pooler.dense.weight]                             \n",
      "\u001b[1mBertModel LOAD REPORT\u001b[0m from: sentence-transformers/all-MiniLM-L6-v2\n",
      "Key                     | Status     |  | \n",
      "------------------------+------------+--+-\n",
      "embeddings.position_ids | UNEXPECTED |  | \n",
      "\n",
      "\u001b[3mNotes:\n",
      "- UNEXPECTED\u001b[3m\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "sentence_model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "# Common business-appropriate emojis with their meanings\n",
    "BUSINESS_EMOJIS = {\n",
    "    \"ðŸ“ˆ\": \"growth, success, improvement\",\n",
    "    \"ðŸ“‰\": \"decline, decrease, loss\",\n",
    "    \"ðŸ‘\": \"approval, agreement, good\",\n",
    "    \"ðŸ¤\": \"agreement, partnership, collaboration\",\n",
    "    \"ðŸ“Š\": \"statistics, analytics, data\",\n",
    "    \"ðŸš€\": \"launch, growth, acceleration\",\n",
    "    \"ðŸ’ª\": \"strength, determination, success\",\n",
    "}\n",
    "\n",
    "\n",
    "def suggest_business_emojis(text, top_k=2):\n",
    "    \"\"\"\n",
    "    Suggest appropriate business emojis for a given text using embedding similarity.\n",
    "\n",
    "    Args:\n",
    "        text (str): Input business text\n",
    "        top_k (int): Number of emoji suggestions to return\n",
    "\n",
    "    Returns:\n",
    "        list: List of tuples (emoji, confidence_score) sorted by confidence\n",
    "\n",
    "    Example:\n",
    "        >>> suggest_business_emojis(\"Our Q4 sales increased by 25%\")\n",
    "        [(\"ðŸ“ˆ\", 0.92), (\"ðŸš€\", 0.85)]\n",
    "    \"\"\"\n",
    "    # Your code here:\n",
    "    # 1. Create embeddings for input text\n",
    "    text_embedding = sentence_model.encode(text)\n",
    "    \n",
    "    # 2. Create embeddings for emoji meanings\n",
    "    emoji_list = list(BUSINESS_EMOJIS.keys())\n",
    "    emoji_meanings = list(BUSINESS_EMOJIS.values())\n",
    "    meaning_embeddings = sentence_model.encode(emoji_meanings)\n",
    "    \n",
    "    # 3. Calculate similarities (cosine similarity)\n",
    "    text_norm = text_embedding / np.linalg.norm(text_embedding)\n",
    "    meaning_norms = meaning_embeddings / np.linalg.norm(meaning_embeddings, axis=1, keepdims=True)\n",
    "    \n",
    "    similarities = np.dot(meaning_norms, text_norm)\n",
    "    \n",
    "    # 4. Return top_k emoji suggestions with confidence scores\n",
    "    top_indices = np.argsort(similarities)[::-1][:top_k]\n",
    "    suggestions = [(emoji_list[idx], float(similarities[idx])) for idx in top_indices]\n",
    "    \n",
    "    return suggestions\n",
    "    \n",
    "    pass\n",
    "\n",
    "\n",
    "\n",
    "# Example business messages\n",
    "business_messages = [\n",
    "    \"We exceeded our quarterly targets by 30%\",\n",
    "    \"New partnership announcement coming soon\",\n",
    "    \"Customer satisfaction ratings dropped this month\",\n",
    "    \"Innovative solution launched for enterprise clients\",\n",
    "    \"Team collaboration has improved significantly\",\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "iblaUFbPEDNH"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Message: We exceeded our quarterly targets by 30%\n",
      "Suggested emojis: [('ðŸ“ˆ', 0.2681995630264282), ('ðŸš€', 0.2089613825082779)]\n",
      "\n",
      "Message: New partnership announcement coming soon\n",
      "Suggested emojis: [('ðŸ¤', 0.6311315894126892), ('ðŸ‘', 0.4295920133590698)]\n",
      "\n",
      "Message: Customer satisfaction ratings dropped this month\n",
      "Suggested emojis: [('ðŸ“‰', 0.20369338989257812), ('ðŸ“Š', 0.1753871738910675)]\n",
      "\n",
      "Message: Innovative solution launched for enterprise clients\n",
      "Suggested emojis: [('ðŸ“ˆ', 0.34140026569366455), ('ðŸ¤', 0.3062551021575928)]\n",
      "\n",
      "Message: Team collaboration has improved significantly\n",
      "Suggested emojis: [('ðŸ¤', 0.5045756697654724), ('ðŸ“ˆ', 0.3936906158924103)]\n"
     ]
    }
   ],
   "source": [
    "# Test your emoji suggestion function\n",
    "for message in business_messages:\n",
    "    print(f\"\\nMessage: {message}\")\n",
    "    print(\"Suggested emojis:\", suggest_business_emojis(message))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tqH1rq4ZEDNI"
   },
   "source": [
    "#### Task 2.2: Analysis Questions\n",
    "Answer the following questions in your report:\n",
    "1. What are the limitations of this emoji suggestion system?\n",
    "2. How could this system be improved for specific business contexts (e.g., customer service vs. internal communication)?\n",
    "3. What are the potential risks of using this automated emoji suggestion system in professional business communications, and how would you mitigate them?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6BXP4REEEDNI"
   },
   "source": [
    "##### your answer here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1->Limited Emoji Dictionary, cannot handle tone adequacy, semantic matching mismatch, and Embedding similarity is not fine tuned for moderate business syntax.\n",
    "\n",
    "2->Stage-aware: Different emojis for greeting vs. resolution Sentiment-averse escalation detection: Flag if emoji might worsen situation.\n",
    "Response templates: Pre-approved emoji combinations.\n",
    "\n",
    "3->Since we are using embedded models the context can be inaccurate at times leading to misinterpretations, as the system is not detecting the sentiment relationship. Over engineering/automation can lead to brand and Reputation risks as well to mitigate these use sentiment relationship layer maybe, market it as an assistant not a decision maker. Final decision makers and risk analysers should be humans."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Mhxig4wNEDNI"
   },
   "source": [
    "#### End of HW\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [
    {
     "file_id": "1FKF8nQXBnASQWecaqcgdvzhc2alxpPNr",
     "timestamp": 1770366462472
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
